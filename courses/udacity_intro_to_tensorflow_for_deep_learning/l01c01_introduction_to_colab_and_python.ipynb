{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## House price prediction"
      ],
      "metadata": {
        "id": "-0qlbnDmKdtK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "Qsi8S_YDKhxo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "housing = pd.read_csv(\"data.csv\")"
      ],
      "metadata": {
        "id": "RoHG8hTiKkWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "housing.head() #makes a table of first 5 entries"
      ],
      "metadata": {
        "id": "cbjY64dkKsuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "housing.info() #gives no of entries"
      ],
      "metadata": {
        "id": "b6_7Ls9PK68_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "housing.describe()  #gives count, mean, min, max etc"
      ],
      "metadata": {
        "id": "Qc8QTjQjK9y7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline #allows displying plot directly in jupyternb instead of a new window"
      ],
      "metadata": {
        "id": "4CRFdDgLLc1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "zGnaWnPdN25b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "housing.hist(bins = 50, figsize=(20,15))"
      ],
      "metadata": {
        "id": "znfwjUK2Oh3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Train-Test splitting"
      ],
      "metadata": {
        "id": "4OWUCa47UEcQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_set, test_set = train_test_split(housing, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "8YgidtyKUGJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Rows in train set: {len(train_set)} \\n Rows in test_set: {len(test_set)}\")"
      ],
      "metadata": {
        "id": "8Tw2ns0FUSXY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
        "for train_index, test_index in split.split(housing, housing['CHAS']):\n",
        "    strat_train_set = housing.loc[train_index]\n",
        "    strat_test_set = housing.loc[test_index]"
      ],
      "metadata": {
        "id": "exNefO_WaHQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5. Correlation Analysis ---\n",
        "\n",
        "# Assuming 'MEDV' is the target variable (Median Value)\n",
        "corr_matrix = housing.corr()\n",
        "print(\"\\nTop features correlated with MEDV:\")\n",
        "print(corr_matrix[\"MEDV\"].sort_values(ascending=False))"
      ],
      "metadata": {
        "id": "7PIQLRpS4pFl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 6. Data Preparation (Feature Engineering & Cleaning) ---\n",
        "\n",
        "# Create copies and separate features (X) and target (y)\n",
        "housing_train = strat_train_set.drop(\"MEDV\", axis=1) # X_train\n",
        "housing_train_labels = strat_train_set[\"MEDV\"].copy() # y_train\n",
        "\n",
        "housing_test = strat_test_set.drop(\"MEDV\", axis=1) # X_test\n",
        "housing_test_labels = strat_test_set[\"MEDV\"].copy() # y_test"
      ],
      "metadata": {
        "id": "L9EXSvuALqad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 7. Handling Missing Data (Imputation) & Feature Scaling using a Pipeline ---\n",
        "\n",
        "# Use SimpleImputer to fill missing values with the median of each column\n",
        "# The median is robust to outliers\n",
        "imputer = SimpleImputer(strategy=\"median\")\n",
        "\n",
        "# We only fit the imputer on the TRAINING data\n",
        "imputer.fit(housing_train)\n",
        "\n",
        "# Transform both training and test sets\n",
        "housing_train_prepared = imputer.transform(housing_train)\n",
        "housing_train_prepared = pd.DataFrame(housing_train_prepared, columns=housing_train.columns, index=housing_train.index)\n",
        "\n",
        "# Check if missing values are handled\n",
        "print(f\"\\nMissing values check after imputation (should be 0): \\n{housing_train_prepared.isnull().sum().sum()}\")\n",
        "\n",
        "# Feature Scaling: Use StandardScaler to scale features (e.g., to a mean of 0 and std dev of 1)\n",
        "# This is crucial for gradient-descent based algorithms\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Create a final pipeline for all transformations (Imputation -> Scaling)\n",
        "# This ensures consistency and prevents data leakage\n",
        "full_pipeline = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy=\"median\")),\n",
        "    ('std_scaler', StandardScaler()),\n",
        "])\n",
        "\n",
        "# Apply the pipeline to the training data\n",
        "housing_train_prepared_scaled = full_pipeline.fit_transform(housing_train)\n",
        "\n",
        "# Apply the fitted pipeline to the test data\n",
        "housing_test_prepared_scaled = full_pipeline.transform(housing_test)"
      ],
      "metadata": {
        "id": "LvfXykjzL6Yy"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "l01c01_introduction_to_colab_and_python.ipynb",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}